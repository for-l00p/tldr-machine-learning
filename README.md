[Google Large Scale NN Project - video] (http://youtu.be/KELYHjq9Gbs)
 - AI is making machines that are intelligent; ML is making machines that learn
 - Deep learning is a modern reincarnation of ANNs, lossely inspired by what (little) we know about the biological brain.
 - DistBelief is Googles large-scale deep learning infrastructure wih two layers of parallelism
 - Deep learning is good to try for machine perception acts
 - If you have a mountain of (labeled) data, benchmark first, then try deep learning
 - If you dont have a mountain of labeled data, you probably should so bootstrap more!
 - Drawbacks to deep learning are large datasets, computaitonal costs, expertise, and interpretability.
 [FULL SUMMARY] (https://github.com/mlaico/tldr-machine-learning/blob/master/googles-large-scale-deep-learning.md)
 
[Ilya Sutskever: A Brief Overview of Deep Learning - post] (http://yyue.blogspot.ca/2015/01/a-brief-overview-of-deep-learning.html)
 - LDNNs are powerful.
 - LDNNs are trainable if we have a very fast computer.
 - So if we have a very large high-quality dataset, we can find the best LDNN for the task. Which will solve the problem, or at least come close to solving it.

